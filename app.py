# /--------------------------\
# |   START OF app.py FILE   |
# \--------------------------/

# --- 1. IMPORTS ---
import streamlit as st
import google.generativeai as genai
import os
import io
import time
from datetime import datetime
import uuid
import traceback
from dotenv import load_dotenv
import PyPDF2
from pydub import AudioSegment
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Tuple
from enum import Enum
from streamlit_pills import pills
from streamlit_ace import st_ace

# --- Local Imports ---
import database

# --- 2. CONSTANTS & CONFIG ---
load_dotenv()

# Configure the Gemini client safely
try:
    if "GEMINI_API_KEY" in os.environ and os.environ["GEMINI_API_KEY"]:
        genai.configure(api_key=os.environ["GEMINI_API_KEY"])
    else:
        st.session_state.config_error = "üî¥ GEMINI_API_KEY not found. Please create a .env file and add your key."
except Exception as e:
    st.session_state.config_error = f"üî¥ Error configuring Google AI Client: {e}"

# Application Constants
MAX_PDF_MB = 25
MAX_AUDIO_MB = 200
CHUNK_WORD_SIZE = 4500
CHUNK_WORD_OVERLAP = 200

# Models & Prompts
AVAILABLE_MODELS = {
    "Gemini 1.5 Flash": "gemini-1.5-flash",
    "Gemini 1.5 Pro": "gemini-1.5-pro",
    "Gemini 2.0 Flash": "gemini-2.0-flash-lite",
    "Gemini 2.5 Flash": "gemini-2.5-flash",
    "Gemini 2.5 Flash Lite": "gemini-2.5-flash-lite",
    "Gemini 2.5 Pro": "gemini-2.5-pro",
}
MEETING_TYPES = ["Expert Meeting", "Earnings Call", "Custom"]
EXPERT_MEETING_OPTIONS = ["Option 1: Detailed & Strict", "Option 2: Less Verbose", "Option 3: Less Verbose + Summary"]
EARNINGS_CALL_MODES = ["Generate New Notes", "Enrich Existing Notes"]

EXPERT_MEETING_CHUNK_BASE = """### **NOTES STRUCTURE**

**(1.) Opening overview or Expert background (Conditional):**
- If the transcript chunk begins with an overview, agenda, or expert intro, include it FIRST as bullet points.
- **DO:** Capture ALL details (names, dates, numbers, titles). Use simple, direct language.
- **DO NOT:** Summarize or include introductions about consulting firms.
- If no intro exists, OMIT this section entirely.

**(2.) Q&A format:**
Structure the main body STRICTLY in Question/Answer format.

**(2.A) Questions:**
-   Extract the clear, primary question and format it in **bold**.

**(2.B) Answers:**
-   Use bullet points (`-`) directly below the question.
-   Each bullet point must convey specific factual information in a clear, complete sentence.
-   **PRIORITY #1: CAPTURE ALL SPECIFICS.** This includes all data, names, examples, monetary values (`$`), percentages (`%`), etc."""

EXPERT_MEETING_CHUNK_BASE_OPTION_2 = """### **PRIMARY DIRECTIVE**
Your goal is to be slightly less verbose and use a more natural sentence flow where possible. However, you must **NEVER** sacrifice factual detail, data, or specifics for the sake of brevity.

### **NOTES STRUCTURE**

**(1.) Opening overview or Expert background (Conditional):**
- If the transcript chunk begins with an overview, agenda, or expert intro, include it FIRST as bullet points.
- **DO:** Capture ALL details (names, dates, numbers, titles).
- **DO NOT:** Summarize.

**(2.) Q&A format:**
Structure the main body in Question/Answer format.

**(2.A) Questions:**
-   Extract the clear, primary question and format it in **bold**.

**(2.B) Answers:**
-   Use bullet points (`-`) directly below the question.
-   Each bullet point must convey specific factual information in a clear, complete sentence.
-   **PRIORITY #1: CAPTURE ALL SPECIFICS.**"""

# --- 3. STATE & DATA MODELS ---
@dataclass
class AppState:
    # User Config
    input_method: str = "Paste Text"
    selected_meeting_type: str = "Expert Meeting"
    selected_note_style: str = "Option 2: Less Verbose"
    earnings_call_mode: str = "Generate New Notes"
    
    # Model Selection
    notes_model: str = "Gemini 1.5 Pro"
    refinement_model: str = "Gemini 1.5 Pro"
    transcription_model: str = "Gemini 1.5 Flash"
    
    # Toggles & Inputs
    refinement_enabled: bool = True
    add_context_enabled: bool = False
    context_input: str = ""
    speaker_1: str = ""
    speaker_2: str = ""
    earnings_call_topics: str = ""
    existing_notes_input: str = ""
    text_input: str = ""
    
    # File & Processing State
    uploaded_file: Optional[Any] = None
    processing: bool = False
    active_note_id: Optional[str] = None
    error_message: Optional[str] = None

# --- 4. CORE PROCESSING & UTILITY FUNCTIONS ---

@st.cache_data(ttl=3600)
def get_file_content(uploaded_file) -> Tuple[Optional[str], str]:
    """Extracts content from an uploaded file. Caches the result."""
    name = uploaded_file.name
    file_bytes = io.BytesIO(uploaded_file.getvalue())
    ext = os.path.splitext(name)[1].lower()
    
    try:
        if ext == ".pdf":
            reader = PyPDF2.PdfReader(file_bytes)
            if reader.is_encrypted: return "Error: PDF is encrypted.", name
            content = "\n".join(page.extract_text() for page in reader.pages if page.extract_text())
            return (content, name) if content else ("Error: No text found in PDF.", name)
        elif ext in [".txt", ".md"]:
            return file_bytes.read().decode("utf-8"), name
        elif ext in [".wav", ".mp3", ".m4a", ".ogg", ".flac"]:
            audio = AudioSegment.from_file(file_bytes)
            return f"Simulated transcription for '{name}' ({len(audio)/1000:.1f}s audio).", name
    except Exception as e:
        return f"Error: Could not process file {name}. Details: {str(e)}", name
    return None, name

def get_dynamic_prompt(state: AppState, transcript_chunk: str) -> str:
    """Constructs the final prompt based on the complete application state."""
    meeting_type = state.selected_meeting_type
    context_section = f"**ADDITIONAL CONTEXT:**\n{state.context_input}" if state.add_context_enabled and state.context_input else ""

    if meeting_type == "Expert Meeting":
        prompt_base = EXPERT_MEETING_CHUNK_BASE_OPTION_2 if state.selected_note_style != "Option 1: Detailed & Strict" else EXPERT_MEETING_CHUNK_BASE
        return f"{prompt_base}\n\n{context_section}\n\n**MEETING TRANSCRIPT CHUNK:**\n{transcript_chunk}"
    
    elif meeting_type == "Earnings Call":
        topic_instructions = state.earnings_call_topics or "Identify logical themes and use them as bold headings."
        if state.earnings_call_mode == "Enrich Existing Notes":
            return f"Enrich the following existing notes based on the new transcript chunk. Focus on these topics: {topic_instructions}\n\n**EXISTING NOTES:**\n{state.existing_notes_input}\n\n**NEW TRANSCRIPT CHUNK:**\n{transcript_chunk}"
        else:
            return f"Generate detailed earnings call notes based on the transcript chunk. Structure your notes under these topics: {topic_instructions}\n\n{context_section}\n\n**TRANSCRIPT CHUNK:**\n{transcript_chunk}"
            
    elif meeting_type == "Custom":
        return f"CUSTOM PROMPT: Please follow user instructions.\n\n{context_section}\n\n**TRANSCRIPT:**\n{transcript_chunk}"
        
    return f"Error: Unknown meeting type '{meeting_type}'"

def validate_inputs(state: AppState) -> Optional[str]:
    """Validates all inputs and returns an error message string if invalid, otherwise None."""
    if state.input_method == "Paste Text" and not state.text_input.strip():
        return "Please paste a transcript or switch to file upload."
    if state.input_method == "Upload File" and not state.uploaded_file:
        return "Please upload a file or switch to pasting text."
    
    if state.uploaded_file and state.uploaded_file.size > MAX_AUDIO_MB * 1024 * 1024:
        return f"File size exceeds the {MAX_AUDIO_MB}MB limit."
        
    if state.selected_meeting_type == "Earnings Call" and state.earnings_call_mode == "Enrich Existing Notes" and not state.existing_notes_input:
        return "Please provide existing notes for enrichment mode."
        
    return None

def process_and_save_task(state: AppState, status_ui):
    """The main processing pipeline. Called within a `st.status` block."""
    start_time = time.time()
    notes_model = genai.GenerativeModel(AVAILABLE_MODELS[state.notes_model])
    refinement_model = genai.GenerativeModel(AVAILABLE_MODELS[state.refinement_model])
    
    status_ui.update(label="Step 1: Preparing Source Content...")
    raw_transcript, file_name = "", "Pasted Text"
    if state.input_method == "Paste Text":
        raw_transcript = state.text_input
    elif state.uploaded_file:
        content, name = get_file_content(state.uploaded_file)
        if content is None or content.startswith("Error:"):
            raise ValueError(content or "Failed to read file content.")
        raw_transcript, file_name = content, name
    
    if not raw_transcript:
        raise ValueError("Source content is empty.")

    final_transcript = raw_transcript
    refined_transcript = None
    total_tokens = 0

    if state.refinement_enabled:
        status_ui.update(label="Step 2: Refining Transcript...")
        speaker_info = f"Speakers are {state.speaker_1} and {state.speaker_2}." if state.speaker_1 and state.speaker_2 else ""
        refine_prompt = f"Refine the following transcript. Correct errors and label speakers if possible. {speaker_info}\n\n{raw_transcript}"
        response = refinement_model.generate_content(refine_prompt)
        refined_transcript = response.text
        final_transcript = refined_transcript
        total_tokens += response.usage_metadata.total_token_count if hasattr(response, 'usage_metadata') else 0

    status_ui.update(label="Step 3: Generating Notes...")
    words = final_transcript.split()
    chunks = [" ".join(words[i:i + CHUNK_WORD_SIZE]) for i in range(0, len(words), CHUNK_WORD_SIZE - CHUNK_WORD_OVERLAP)]
    
    all_notes = []
    for i, chunk in enumerate(chunks):
        if len(chunks) > 1:
            status_ui.update(label=f"Step 3: Generating Notes (Chunk {i+1}/{len(chunks)})...")
        prompt = get_dynamic_prompt(state, chunk)
        response = notes_model.generate_content(prompt)
        all_notes.append(response.text)
        total_tokens += response.usage_metadata.total_token_count if hasattr(response, 'usage_metadata') else 0

    final_notes_content = "\n\n---\n\n".join(all_notes)
    
    if state.selected_note_style == "Option 3: Less Verbose + Summary":
        status_ui.update(label="Step 4: Generating Executive Summary...")
        summary_prompt = f"Create a concise executive summary from these notes:\n\n{final_notes_content}"
        response = notes_model.generate_content(summary_prompt)
        final_notes_content += f"\n\n---\n\n**EXECUTIVE SUMMARY:**\n\n{response.text}"
        total_tokens += response.usage_metadata.total_token_count if hasattr(response, 'usage_metadata') else 0

    status_ui.update(label="Step 5: Saving to Database...")
    note_data = {
        'id': str(uuid.uuid4()), 'created_at': datetime.now().isoformat(), 'meeting_type': state.selected_meeting_type,
        'file_name': file_name, 'content': final_notes_content, 'raw_transcript': raw_transcript,
        'refined_transcript': refined_transcript, 'token_usage': total_tokens, 'processing_time': time.time() - start_time
    }
    database.save_note(note_data)
    return note_data

# --- 5. UI RENDERING FUNCTIONS ---

def render_input_and_processing_tab(state: AppState):
    # --- Part 1: All Inputs and Configuration ---
    state.input_method = pills("Input Method", ["Paste Text", "Upload File"], index=["Paste Text", "Upload File"].index(state.input_method))
    
    if state.input_method == "Paste Text":
        state.text_input = st.text_area("Paste source transcript here:", height=250, key="text_input_main")
        state.uploaded_file = None
    else:
        state.uploaded_file = st.file_uploader("Upload a File (PDF, TXT, MP3, etc.)", type=['pdf', 'wav', 'mp3', 'm4a', 'txt'])
        state.text_input = ""

    st.subheader("Configuration")
    state.selected_meeting_type = st.selectbox("Meeting Type", MEETING_TYPES, index=MEETING_TYPES.index(state.selected_meeting_type))
    
    if state.selected_meeting_type == "Expert Meeting":
        state.selected_note_style = st.selectbox("Note Style", EXPERT_MEETING_OPTIONS, index=EXPERT_MEETING_OPTIONS.index(state.selected_note_style))
    elif state.selected_meeting_type == "Earnings Call":
        state.earnings_call_mode = st.radio("Mode", EARNINGS_CALL_MODES, horizontal=True, index=EARNINGS_CALL_MODES.index(state.earnings_call_mode))
        if state.earnings_call_mode == "Enrich Existing Notes":
            state.existing_notes_input = st.text_area("Paste Existing Notes to Enrich:", value=state.existing_notes_input)
        state.earnings_call_topics = st.text_area("Topic Instructions (Optional)", value=state.earnings_call_topics, placeholder="One topic per line...")

    with st.expander("‚öôÔ∏è Advanced Settings & Models"):
        state.refinement_enabled = st.toggle("Enable Transcript Refinement", value=state.refinement_enabled)
        state.add_context_enabled = st.toggle("Add General Context", value=state.add_context_enabled)
        if state.add_context_enabled:
            state.context_input = st.text_area("Context Details:", value=state.context_input, placeholder="e.g., Company Name, Date...")
        
        c1, c2 = st.columns(2)
        state.speaker_1 = c1.text_input("Speaker 1 Name (Optional)", value=state.speaker_1)
        state.speaker_2 = c2.text_input("Speaker 2 Name (Optional)", value=state.speaker_2)

        st.markdown("**Model Selection**")
        m1, m2, m3 = st.columns(3)
        state.notes_model = m1.selectbox("Notes Model", list(AVAILABLE_MODELS.keys()), index=list(AVAILABLE_MODELS.keys()).index(state.notes_model))
        state.refinement_model = m2.selectbox("Refinement Model", list(AVAILABLE_MODELS.keys()), index=list(AVAILABLE_MODELS.keys()).index(state.refinement_model))
        state.transcription_model = m3.selectbox("Transcription Model", list(AVAILABLE_MODELS.keys()), index=list(AVAILABLE_MODELS.keys()).index(state.transcription_model), help="Used for audio files.")
    
    st.subheader("Prompt Preview")
    prompt_preview = get_dynamic_prompt(state, "[...transcript content will be inserted here...]")
    st_ace(value=prompt_preview, language='markdown', theme='github', height=200, readonly=True, key="prompt_preview_ace")
    
    st.divider()

    # --- Part 2: Processing Logic ---
    st.subheader("üöÄ Generate")
    validation_error = validate_inputs(state)
    
    if st.button("Generate Notes", type="primary", use_container_width=True, disabled=bool(validation_error)):
        state.processing = True
        state.error_message = None
        st.rerun()

    if validation_error:
        st.warning(f"‚ö†Ô∏è Please fix the following: {validation_error}")
        
    if state.processing:
        with st.status("Processing your request...", expanded=True) as status:
            try:
                final_note = process_and_save_task(state, status)
                state.active_note_id = final_note['id']
                status.update(label="‚úÖ Success! View your note in the 'Output & History' tab.", state="complete")
            except Exception as e:
                state.error_message = f"{e}\n\n{traceback.format_exc()}"
                status.update(label=f"‚ùå Error: {e}", state="error")
        state.processing = False

    if state.error_message:
        st.error("Last run failed. See details below:")
        st.code(state.error_message)

def render_output_and_history_tab(state: AppState):
    # --- Part 1: Active Note Output ---
    st.subheader("üìÑ Active Note")
    notes = database.get_all_notes()
    if not notes:
        st.info("No notes have been generated yet. Go to the 'Input & Generate' tab to create one.")
        return
        
    if not state.active_note_id or not any(n['id'] == state.active_note_id for n in notes):
        state.active_note_id = notes[0]['id']

    active_note = next((n for n in notes if n['id'] == state.active_note_id), notes[0])
    
    st.markdown(f"**Viewing Note for:** `{active_note['file_name']}`")
    st.caption(f"ID: {active_note['id']} | Generated: {datetime.fromisoformat(active_note['created_at']).strftime('%Y-%m-%d %H:%M')}")
    
    edited_content = st_ace(value=active_note['content'], language='markdown', theme='github', height=600, key=f"output_ace_{active_note['id']}")
    
    with st.expander("View Source Transcripts"):
        if active_note['refined_transcript']:
            st.text_area("Refined Transcript", value=active_note['refined_transcript'], height=200, disabled=True, key=f"refined_tx_{active_note['id']}")
        if active_note['raw_transcript']:
            st.text_area("Raw Source", value=active_note['raw_transcript'], height=200, disabled=True, key=f"raw_tx_{active_note['id']}")
            
    st.divider()

    # --- Part 2: Analytics and History ---
    st.subheader("üìä Analytics & History")
    summary = database.get_analytics_summary()
    
    c1, c2, c3 = st.columns(3)
    c1.metric("Total Notes in DB", summary['total_notes'])
    c2.metric("Avg. Time / Note", f"{summary['avg_time']:.1f}s")
    c3.metric("Total Tokens (Est.)", f"{summary['total_tokens']:,}")

    for note in notes:
        with st.container(border=True):
            col1, col2 = st.columns([4, 1])
            with col1:
                st.markdown(f"**File:** `{note['file_name']}` ({note['meeting_type']})")
                st.caption(f"ID: {note['id']} | {datetime.fromisoformat(note['created_at']).strftime('%Y-%m-%d %H:%M')}")
            with col2:
                if st.button("Set as Active", key=f"view_{note['id']}", use_container_width=True):
                    state.active_note_id = note['id']
                    st.rerun()
            
            with st.expander("Preview"):
                st.markdown(note['content'])

# --- 6. MAIN APPLICATION RUNNER ---
def run_app():
    st.set_page_config(page_title="SynthNotes AI üöÄ", layout="wide")
    st.title("SynthNotes AI üöÄ")
    
    if "config_error" in st.session_state:
        st.error(st.session_state.config_error)
        st.stop()
        
    try:
        database.init_db()
        if "app_state" not in st.session_state:
            st.session_state.app_state = AppState()

        tabs = st.tabs(["üìù Input & Generate", "üìÑ Output & History"])
        
        with tabs[0]: render_input_and_processing_tab(st.session_state.app_state)
        with tabs[1]: render_output_and_history_tab(st.session_state.app_state)
    
    except Exception as e:
        st.error("A critical application error occurred.")
        st.code(traceback.format_exc())

if __name__ == "__main__":
    run_app()

# /------------------------\
# |   END OF app.py FILE   |
# \------------------------/
